{"version":3,"sources":["webpack:///./src/views/Paper.vue?02ae","webpack:///src/views/Paper.vue","webpack:///./src/views/Paper.vue?2d0f","webpack:///./src/views/Paper.vue","webpack:///./src/views/Paper.vue?bb44"],"names":["render","_vm","this","_h","$createElement","_c","_self","staticClass","_m","_v","attrs","on","$event","toPaperDetail","staticStyle","staticRenderFns","component"],"mappings":"yHAAA,IAAIA,EAAS,WAAa,IAAIC,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,aAAa,CAACN,EAAIO,GAAG,GAAGH,EAAG,MAAM,CAACE,YAAY,WAAW,CAACF,EAAG,MAAM,CAACA,EAAG,IAAI,CAACE,YAAY,SAAS,CAACN,EAAIQ,GAAG,4EAA4EJ,EAAG,IAAI,CAACE,YAAY,SAAS,CAACN,EAAIQ,GAAG,+CAA+CJ,EAAG,WAAW,CAACE,YAAY,UAAUG,MAAM,CAAC,KAAO,QAAQC,GAAG,CAAC,MAAQ,SAASC,GAAQ,OAAOX,EAAIY,cAAc,sBAAsB,CAACZ,EAAIQ,GAAG,gBAAgB,GAAGJ,EAAG,MAAMJ,EAAIO,GAAG,GAAGP,EAAIO,GAAG,GAAGH,EAAG,YAAY,CAACS,YAAY,CAAC,OAAS,SAAS,mBAAmB,iHAAiHT,EAAG,OAAO,GAAGA,EAAG,MAAM,CAACA,EAAG,IAAI,CAACE,YAAY,SAAS,CAACN,EAAIQ,GAAG,mDAAmDJ,EAAG,WAAW,CAACE,YAAY,UAAUG,MAAM,CAAC,KAAO,QAAQC,GAAG,CAAC,MAAQ,SAASC,GAAQ,OAAOX,EAAIY,cAAc,qDAAqD,CAACZ,EAAIQ,GAAG,gBAAgB,GAAGJ,EAAG,MAAMJ,EAAIO,GAAG,GAAGP,EAAIO,GAAG,GAAGH,EAAG,YAAY,CAACS,YAAY,CAAC,OAAS,SAAS,mBAAmB,iHAAiHT,EAAG,OAAO,QACvvCU,EAAkB,CAAC,WAAa,IAAId,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,UAAU,CAACF,EAAG,MAAM,CAACS,YAAY,CAAC,cAAc,OAAO,MAAQ,UAAU,CAACT,EAAG,IAAI,CAACS,YAAY,CAAC,OAAS,oBAAoB,YAAY,SAAS,CAACb,EAAIQ,GAAG,WAAWJ,EAAG,IAAI,CAACS,YAAY,CAAC,OAAS,mBAAmB,YAAY,SAAS,CAACb,EAAIQ,GAAG,8DAA8D,WAAa,IAAIR,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,IAAI,CAACJ,EAAIQ,GAAG,2EAA2EJ,EAAG,MAAMA,EAAG,IAAI,CAACA,EAAG,IAAI,CAACJ,EAAIQ,GAAG,sBAAsBR,EAAIQ,GAAG,QAAQ,WAAa,IAAIR,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,IAAI,CAACA,EAAG,IAAI,CAACJ,EAAIQ,GAAG,cAAcR,EAAIQ,GAAG,khDAAkhD,WAAa,IAAIR,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,IAAI,CAACJ,EAAIQ,GAAG,sEAAsEJ,EAAG,MAAMA,EAAG,IAAI,CAACA,EAAG,IAAI,CAACJ,EAAIQ,GAAG,yHAAyHR,EAAIQ,GAAG,QAAQ,WAAa,IAAIR,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,IAAI,CAACA,EAAG,IAAI,CAACJ,EAAIQ,GAAG,cAAcR,EAAIQ,GAAG,+lCCwClwF,GACE,KADF,WAEI,MAAJ,IAGE,WAAF,GAEE,QAAF,CACI,cADJ,SACA,GACM,KAAN,cACQ,KAAR,OCnD+U,I,wBCQ3UO,EAAY,eACd,EACAhB,EACAe,GACA,EACA,KACA,WACA,MAIa,aAAAC,E,sECnBf","file":"js/chunk-9d351324.d77a3eb8.js","sourcesContent":["var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"container\"},[_vm._m(0),_c('div',{staticClass:\"content\"},[_c('div',[_c('p',{staticClass:\"title\"},[_vm._v(\"Towards Efficient and Comprehensive Urban Spatial-Temporal Prediction:\")]),_c('p',{staticClass:\"title\"},[_vm._v(\"A Unified Library and Performance Benchmark\"),_c('a-button',{staticClass:\"details\",attrs:{\"type\":\"link\"},on:{\"click\":function($event){return _vm.toPaperDetail('LibCity-Journal')}}},[_vm._v(\"[Details]\")])],1),_c('br'),_vm._m(1),_vm._m(2),_c('a-divider',{staticStyle:{\"margin\":\"10px 0\",\"background-image\":\"linear-gradient(to right,  rgb(103, 179, 241),  rgb(103, 179, 241), rgb(103, 179, 241), rgb(103, 179, 241))\"}}),_c('br')],1),_c('div',[_c('p',{staticClass:\"title\"},[_vm._v(\"LibCity: An Open Library for Traffic Prediction\"),_c('a-button',{staticClass:\"details\",attrs:{\"type\":\"link\"},on:{\"click\":function($event){return _vm.toPaperDetail('LibCity-An-Open-Library-For-Traffic-Prediction')}}},[_vm._v(\"[Details]\")])],1),_c('br'),_vm._m(3),_vm._m(4),_c('a-divider',{staticStyle:{\"margin\":\"10px 0\",\"background-image\":\"linear-gradient(to right,  rgb(103, 179, 241),  rgb(103, 179, 241), rgb(103, 179, 241), rgb(103, 179, 241))\"}}),_c('br')],1)])])}\nvar staticRenderFns = [function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"header\"},[_c('div',{staticStyle:{\"padding-top\":\"20px\",\"color\":\"white\"}},[_c('p',{staticStyle:{\"margin\":\"20px 0 30px 130px\",\"font-size\":\"60px\"}},[_vm._v(\"Paper\")]),_c('p',{staticStyle:{\"margin\":\"0px 0 20px 130px\",\"font-size\":\"30px\"}},[_vm._v(\" This page provides the related papers of LibCity. \")])])])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Jingyuan Wang, Jiawei Jiang, Wenjun Jiang, Chengkai Han, Wayne Xin Zhao\"),_c('br'),_c('b',[_c('i',[_vm._v(\"arXiv preprint\")])]),_vm._v(\".\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_c('b',[_vm._v(\"Abstract\")]),_vm._v(\": As deep learning technology advances and more urban spatial-temporal data accumulates, an increasing number of deep learning models are being proposed to solve urban spatial-temporal prediction problems. However, there are limitations in the existing field, including open-source data being in various formats and difficult to use, few papers making their code and data openly available, and open-source models often using different frameworks and platforms, making comparisons challenging. A standardized framework is urgently needed to implement and evaluate these methods. To address these issues, we provide a comprehensive review of urban spatial-temporal prediction and propose a unified storage format for spatial-temporal data called atomic files. We also propose LibCity, an open-source library that offers researchers a credible experimental tool and a convenient development framework. In this library, we have reproduced 65 spatial-temporal prediction models and collected 55 spatial-temporal datasets, allowing researchers to conduct comprehensive experiments conveniently. Using LibCity, we conducted a series of experiments to validate the effectiveness of different models and components, and we summarized promising future technology developments and research directions for spatial-temporal prediction. By enabling fair model comparisons, designing a unified data storage format, and simplifying the process of developing new models, LibCity is poised to make significant contributions to the spatial-temporal prediction field.\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_vm._v(\"Jingyuan Wang, Jiawei Jiang, Wenjun Jiang, Chao Li, Wayne Xin Zhao\"),_c('br'),_c('b',[_c('i',[_vm._v(\"In Proceedings of the 29th International Conference on Advances in Geographic Information Systems (SIGSPATIAL'21)\")])]),_vm._v(\".\")])},function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('p',[_c('b',[_vm._v(\"Abstract\")]),_vm._v(\": With the increase of traffic prediction models, there has become an urgent need to develop a standardized framework to implement and evaluate these methods. This paper presents LibCity, a unified, comprehensive, and extensible library for traffic prediction, which provides researchers with a credible experimental tool and a convenient development framework. In this library, we reproduce 42 traffic prediction models and collect 29 spatial-temporal datasets, which allows researchers to conduct comprehensive experiments in a convenient way. To accelerate the development of new models, we design unified model interfaces based on unified data formats, which effectively encapsulate the details of the implementation. To verify the effectiveness of our implementations, we also report the reproducibility comparison results of LibCity, and set up a performance leaderboard for the four kinds of traffic prediction tasks. Our library will contribute to the standardization and reproducibility in the field of traffic prediction. The open source link of LibCity is https://github.com/LibCity/Bigscity-LibCity.\")])}]\n\nexport { render, staticRenderFns }","<template>\r\n  <div class=\"container\">\r\n    <div class=\"header\">\r\n      <div style=\"padding-top: 20px;color: white;\">\r\n        <p style=\"margin: 20px 0 30px 130px; font-size: 60px\">Paper</p>\r\n        <p style=\"margin: 0px 0 20px 130px; font-size: 30px\">\r\n          This page provides the related papers of LibCity.\r\n        </p>\r\n      </div>\r\n    </div>\r\n    <div class=\"content\">\r\n        <div>\r\n            <p class=\"title\">Towards Efficient and Comprehensive Urban Spatial-Temporal Prediction:</p>\r\n            <p class=\"title\">A Unified Library and Performance Benchmark<a-button type=\"link\" class=\"details\" @click=\"toPaperDetail('LibCity-Journal')\">[Details]</a-button></p>\r\n            <br>\r\n            <!-- <p>\r\n              <a-button type=\"link\" class=\"title\" @click=\"toPaperDetail('LibCity-Journal')\">Towards Efficient and Comprehensive Urban Spatial-Temporal Prediction: A Unified Library and Performance Benchmark</a-button>\r\n            </p> -->\r\n            <p>Jingyuan Wang, Jiawei Jiang, Wenjun Jiang, Chengkai Han, Wayne Xin Zhao<br>\r\n            <b><i>arXiv preprint</i></b>.</p>\r\n            <p><b>Abstract</b>: As deep learning technology advances and more urban spatial-temporal data accumulates, an increasing number of deep learning models are being proposed to solve urban spatial-temporal prediction problems. However, there are limitations in the existing field, including open-source data being in various formats and difficult to use, few papers making their code and data openly available, and open-source models often using different frameworks and platforms, making comparisons challenging. A standardized framework is urgently needed to implement and evaluate these methods. To address these issues, we provide a comprehensive review of urban spatial-temporal prediction and propose a unified storage format for spatial-temporal data called atomic files. We also propose LibCity, an open-source library that offers researchers a credible experimental tool and a convenient development framework. In this library, we have reproduced 65 spatial-temporal prediction models and collected 55 spatial-temporal datasets, allowing researchers to conduct comprehensive experiments conveniently. Using LibCity, we conducted a series of experiments to validate the effectiveness of different models and components, and we summarized promising future technology developments and research directions for spatial-temporal prediction. By enabling fair model comparisons, designing a unified data storage format, and simplifying the process of developing new models, LibCity is poised to make significant contributions to the spatial-temporal prediction field.</p>\r\n            <a-divider style=\"margin: 10px 0; background-image: linear-gradient(to right,  rgb(103, 179, 241),  rgb(103, 179, 241), rgb(103, 179, 241), rgb(103, 179, 241));\"></a-divider>\r\n            <br>\r\n        </div>\r\n        <div>\r\n            <p class=\"title\">LibCity: An Open Library for Traffic Prediction<a-button type=\"link\" class=\"details\" @click=\"toPaperDetail('LibCity-An-Open-Library-For-Traffic-Prediction')\">[Details]</a-button></p>\r\n            <!-- <p>\r\n              <a-button type=\"link\" class=\"title\" @click=\"toPaperDetail('LibCity-An-Open-Library-For-Traffic-Prediction')\">LibCity: An Open Library for Traffic Prediction</a-button>\r\n            </p> -->\r\n            <br>\r\n            <p>Jingyuan Wang, Jiawei Jiang, Wenjun Jiang, Chao Li, Wayne Xin Zhao<br>\r\n            <b><i>In Proceedings of the 29th International Conference on Advances in Geographic Information Systems (SIGSPATIAL'21)</i></b>.</p>\r\n            <p><b>Abstract</b>: With the increase of traffic prediction models, there has become an urgent need to develop a standardized framework to implement and evaluate these methods. This paper presents LibCity, a unified, comprehensive, and extensible library for traffic prediction, which provides researchers with a credible experimental tool and a convenient development framework. In this library, we reproduce 42 traffic prediction models and collect 29 spatial-temporal datasets, which allows researchers to conduct comprehensive experiments in a convenient way. To accelerate the development of new models, we design unified model interfaces based on unified data formats, which effectively encapsulate the details of the implementation. To verify the effectiveness of our implementations, we also report the reproducibility comparison results of LibCity, and set up a performance leaderboard for the four kinds of traffic prediction tasks. Our library will contribute to the standardization and reproducibility in the field of traffic prediction. The open source link of LibCity is https://github.com/LibCity/Bigscity-LibCity.</p>\r\n            <a-divider style=\"margin: 10px 0; background-image: linear-gradient(to right,  rgb(103, 179, 241),  rgb(103, 179, 241), rgb(103, 179, 241), rgb(103, 179, 241));\"></a-divider>\r\n            <br>\r\n        </div>\r\n    </div>\r\n  </div>\r\n</template>\r\n\r\n<script>\r\n    export default {\r\n        data() {\r\n            return {\r\n            };\r\n        },\r\n        components: {\r\n        },\r\n        methods: {\r\n            toPaperDetail(paper) {\r\n                this.$router.push({\r\n                    name: paper,\r\n                });\r\n            },\r\n        }\r\n    };\r\n</script>\r\n\r\n<style scoped>\r\n.container {\r\n  margin: auto;\r\n  width: 100%;\r\n  height: auto;\r\n  /* border: red solid 1px; */\r\n}\r\n.header {\r\n  width: 100%;\r\n  height: 250px;\r\n  background:  rgb(27, 140, 233) linear-gradient(to right,  rgb(27, 140, 233), rgb(11, 247, 188));\r\n  /* border: blue solid 1px; */\r\n}\r\n.content {\r\n    width: 80%;\r\n    height: auto;\r\n    margin: 50px auto 0 auto;\r\n    font-size: 20px;\r\n    line-height: 36px;\r\n    color: black;\r\n    font-family: 'Open Sans', 'Microsoft YaHei', Arial, Helvetica, sans-serif;\r\n    /* border: blue solid 3px; */\r\n}\r\n.title {\r\n    font-size: 32px;\r\n    font-weight: 700;\r\n    font-family: 'Open Sans', 'Microsoft YaHei', Arial, Helvetica, sans-serif;\r\n    padding: 0;\r\n    margin-bottom: 0px;\r\n    line-height: 36px;\r\n    color: black;\r\n}\r\n.details {\r\n  font-size: 24px;\r\n}\r\n/* .title:hover {\r\n    color: rgb(27, 140, 233);\r\n} */\r\n</style>","import mod from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Paper.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--12-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Paper.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./Paper.vue?vue&type=template&id=036ec294&scoped=true&\"\nimport script from \"./Paper.vue?vue&type=script&lang=js&\"\nexport * from \"./Paper.vue?vue&type=script&lang=js&\"\nimport style0 from \"./Paper.vue?vue&type=style&index=0&id=036ec294&scoped=true&lang=css&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  \"036ec294\",\n  null\n  \n)\n\nexport default component.exports","export * from \"-!../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--6-oneOf-1-0!../../node_modules/css-loader/dist/cjs.js??ref--6-oneOf-1-1!../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../node_modules/postcss-loader/src/index.js??ref--6-oneOf-1-2!../../node_modules/cache-loader/dist/cjs.js??ref--0-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Paper.vue?vue&type=style&index=0&id=036ec294&scoped=true&lang=css&\""],"sourceRoot":""}