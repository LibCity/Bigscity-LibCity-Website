(window["webpackJsonp"]=window["webpackJsonp"]||[]).push([["chunk-dd38305c"],{1286:function(e,a,t){"use strict";t.r(a);var i=function(){var e=this,a=e._self._c;return a("div",{staticClass:"content"},[a("div",[a("br"),a("p",{staticClass:"title"},[e._v("Towards Efficient and Comprehensive Urban Spatial-Temporal Prediction: A Unified Library and Performance Benchmark")]),e._m(0),e._m(1),a("p",{staticClass:"second-title"},[e._v("Abstract")]),a("a-divider",{staticStyle:{margin:"10px 0","background-image":"linear-gradient(to right,  rgb(103, 179, 241),  rgb(103, 179, 241), #f6f6f6, #f6f6f6)"}}),a("p",[e._v("As deep learning technology advances and more urban spatial-temporal data accumulates, an increasing number of deep learning models are being proposed to solve urban spatial-temporal prediction problems. However, there are limitations in the existing field, including open-source data being in various formats and difficult to use, few papers making their code and data openly available, and open-source models often using different frameworks and platforms, making comparisons challenging. A standardized framework is urgently needed to implement and evaluate these methods. To address these issues, we provide a comprehensive review of urban spatial-temporal prediction and propose a unified storage format for spatial-temporal data called atomic files. We also propose LibCity, an open-source library that offers researchers a credible experimental tool and a convenient development framework. In this library, we have reproduced 65 spatial-temporal prediction models and collected 55 spatial-temporal datasets, allowing researchers to conduct comprehensive experiments conveniently. Using LibCity, we conducted a series of experiments to validate the effectiveness of different models and components, and we summarized promising future technology developments and research directions for spatial-temporal prediction. By enabling fair model comparisons, designing a unified data storage format, and simplifying the process of developing new models, LibCity is poised to make significant contributions to the spatial-temporal prediction field.")]),a("br"),e._m(2),a("p",{staticClass:"second-title"},[e._v("Cite")]),a("a-divider",{staticStyle:{margin:"10px 0","background-image":"linear-gradient(to right,  rgb(103, 179, 241),  rgb(103, 179, 241), #f6f6f6, #f6f6f6)"}}),a("p",[e._v("If you find our work useful for your research or development, please cite our paper.")]),e._m(3),a("br")],1)])},n=[function(){var e=this,a=e._self._c;return a("p",[a("a",{attrs:{href:"https://arxiv.org/abs/2304.14343",target:"_blank"}},[e._v("[Official Link]")]),e._v(" "),a("a",{attrs:{href:"https://github.com/LibCity",target:"_blank"}},[e._v("[Code]")])])},function(){var e=this,a=e._self._c;return a("p",[e._v("Jingyuan Wang, Jiawei Jiang, Wenjun Jiang, Chengkai Han, Wayne Xin Zhao"),a("br"),a("b",[a("i",[e._v("arXiv preprint.")])])])},function(){var e=this,a=e._self._c;return a("div",{staticStyle:{width:"80%",margin:"5px auto","text-align":"center"}},[a("img",{attrs:{src:t("8e59"),alt:"framework",height:"400"}})])},function(){var e=this,a=e._self._c;return a("div",{staticClass:"code"},[a("code",[a("p",[e._v("@article{libcitylong,")]),a("p",{staticStyle:{"text-indent":"2em"}},[e._v("title={Towards Efficient and Comprehensive Urban Spatial-Temporal Prediction: A Unified Library and Performance Benchmark},")]),a("p",{staticStyle:{"text-indent":"2em"}},[e._v("author={Jingyuan Wang and Jiawei Jiang and Wenjun Jiang and Chengkai Han and Wayne Xin Zhao},")]),a("p",{staticStyle:{"text-indent":"2em"}},[e._v("journal={arXiv preprint arXiv:2304.14343},")]),a("p",{staticStyle:{"text-indent":"2em"}},[e._v("year={2023}")]),a("p",[e._v("}")])])])}],r={data(){return{path:""}},components:{}},o=r,s=(t("380e"),t("1805")),d=Object(s["a"])(o,i,n,!1,null,"86e2eb0c",null);a["default"]=d.exports},"1b1d":function(e,a,t){},"380e":function(e,a,t){"use strict";t("1b1d")},"8e59":function(e,a,t){e.exports=t.p+"img/framework.85b623a8.png"}}]);
//# sourceMappingURL=chunk-dd38305c.bbfd8ecd.js.map